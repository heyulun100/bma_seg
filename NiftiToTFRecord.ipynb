{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c28169f",
   "metadata": {},
   "source": [
    "# Creating tf records\n",
    "## For the training of a deep learning model in tensorflow we should encode our data into .tfrecord files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc69780",
   "metadata": {},
   "source": [
    "### The basic idea of our record writer is to follow the tf.train.Example format presented here https://www.tensorflow.org/tutorials/load_data/tfrecord"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb0b222",
   "metadata": {},
   "source": [
    "### This format is similar to that of a dictionary, with each key being a string name of a particular feature. For example, an image might be {'image': np_array}, where np_array is convereted into a tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1bfbb0",
   "metadata": {},
   "source": [
    "## Creating a dictionary for record writing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e483548",
   "metadata": {},
   "source": [
    "### Lets start with an example of an image and a mask for image segmentation. If you already have an image and mask, change the paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033cdbe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from Base_Deeplearning_Code.Plot_And_Scroll_Images.Plot_Scroll_Images import plot_Image_Scroll_Bar_Image\n",
    "import SimpleITK as sitk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cda0ed16",
   "metadata": {},
   "outputs": [],
   "source": [
    "record_path = r'H:\\TF_Record_Exports'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f346f8",
   "metadata": {},
   "source": [
    "### If you have an image and annotation path, lets list them here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0809f969",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dictionary_list = []\n",
    "files = [i for i in os.listdir(nifti_path) if i.startswith('Overall_Data')]\n",
    "for file in files:\n",
    "    index = file.split('_')[-1].split('.nii')[0]\n",
    "    image_path = os.path.join(nifti_path, file)\n",
    "    annotation_path = os.path.join(nifti_path, 'Overall_mask_Test_y{}.nii.gz'.format(index))\n",
    "    temp_dict = {'image_path': image_path, 'annotation_path':annotation_path, 'out_name': '{}.tfrecord'.format(index)}\n",
    "    file_dictionary_list.append(temp_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97df0ce",
   "metadata": {},
   "source": [
    "This should be a list of paths to images and annotations, as well as an out_name for the tf record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664c3261",
   "metadata": {},
   "outputs": [],
   "source": [
    "example = file_dictionary_list[-1]\n",
    "example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c37c0b",
   "metadata": {},
   "source": [
    "### We are going to handle everything through a series of image processors, the base class for ImageProcessor is given below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aca2a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageProcessor(object):\n",
    "    def pre_process(self, input_features):\n",
    "        return input_features\n",
    "\n",
    "    def post_process(self, input_features):\n",
    "        return input_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b317dd",
   "metadata": {},
   "source": [
    "## The pre_process should be any encoding, like normalization\n",
    "## The post_process should be anything for decoding, and is normally reserved for ensuring the image dimensions go back to what they were previously"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ed2a23",
   "metadata": {},
   "source": [
    "### The first thing we need to do is to load the images as nifti files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f17583",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Base_Deeplearning_Code.Image_Processors_Module.src.Processors import MakeTFRecordProcessors as Processors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14954c6",
   "metadata": {},
   "source": [
    "### We want to do two things: First, take a set of paths and load the images. Second, convert those handles into arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6676deea",
   "metadata": {},
   "outputs": [],
   "source": [
    "processors = [\n",
    "    Processors.LoadNifti(nifti_path_keys=('image_path', 'annotation_path'),  # Loads a file path as a SimpleITK Image\n",
    "                         out_keys=('image_handle', 'annotation_handle')),\n",
    "    Processors.SimpleITKImageToArray(nifti_keys=('image_handle', 'annotation_handle'),  # Converts an Image to array\n",
    "                                      out_keys=('image_array', 'annotation_array'), dtypes=('float32', 'int8'))\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28bc4b15",
   "metadata": {},
   "source": [
    "### Run through each processors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb178b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in processors:\n",
    "    example = p.pre_process(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef92a2ef",
   "metadata": {},
   "source": [
    "### View the keys\n",
    "Note that we have several keys now, path information, image handles, arrays, as well as spacing information! NumPy arrays do not have spacing information, and so the keys are automatically added when converting a Nifti to Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b637351",
   "metadata": {},
   "outputs": [],
   "source": [
    "example.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e295b83",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_Image_Scroll_Bar_Image(example['image_array'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25893f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_Image_Scroll_Bar_Image(example['annotation_array'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a8eabb",
   "metadata": {},
   "source": [
    "### Now that we have our image and annotation, lets perform some pre-processing\n",
    "### We do not need all of the keys present, and SITK handles are not able to be encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7d2831",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizing_processors = [\n",
    "    Processors.DeleteKeys(keys_to_delete=('image_handle', 'annotation_handle')),\n",
    "    Processors.Threshold_Images(image_keys=('image_array',), lower_bound=-100, upper_bound=200),\n",
    "    Processors.Box_Images(image_keys=('image_array',), annotation_key='annotation_array',wanted_vals_for_bbox=(1,),\n",
    "                          bounding_box_expansion=(0, 0, 0), power_val_z=1, power_val_r=512,\n",
    "                          power_val_c=512, min_images=None, min_rows=None, min_cols=None)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad68ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in normalizing_processors:\n",
    "    example = p.pre_process(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3df215",
   "metadata": {},
   "source": [
    "### Lets make this a 2D model generator, so we now need to distribute these images into 2D slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01316d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "distribution_processors = [\n",
    "    Processors.DistributeInTo2DSlices(image_keys=('image_array', 'annotation_array'))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3695806",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in distribution_processors:\n",
    "    example = p.pre_process(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff55e07",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_Image_Scroll_Bar_Image(example[20]['image_array'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc44a589",
   "metadata": {},
   "source": [
    "## Write dictionary as .tfrecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73b9aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Base_Deeplearning_Code.Image_Processors_Module.src.Processors import TFRecordWriter as Writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ce3988",
   "metadata": {},
   "outputs": [],
   "source": [
    "record_writer = Writer.RecordWriter(out_path=record_path, file_name_key='out_name', rewrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2da0489",
   "metadata": {},
   "outputs": [],
   "source": [
    "record_writer.write_records(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146ffc4d",
   "metadata": {},
   "source": [
    "## Writing the records in parallel\n",
    "There is no reason that we should have to go through each of these nifti files individually. Instead, we have a function to run these in parallel for all steps listed above. Just pass along our list of dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d937775",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_records = 2  # Just write two out\n",
    "Writer.parallel_record_writer(dictionary_list=file_dictionary_list, max_records=max_records,\n",
    "                              image_processors=processors + normalizing_processors + distribution_processors,\n",
    "                              recordwriter=record_writer, verbose=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
